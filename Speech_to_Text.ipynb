{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kararmirza19/kararmirza19/blob/main/Speech_to_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3hAPy_id6s6",
        "outputId": "d06606ff-565c-4d85-a722-c8dd0ec6d5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.10/dist-packages (2.26.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.11.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk google-cloud-speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeALo2nKVcrD",
        "outputId": "431f8bf0-52fe-40ae-a6b1-02c262388c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: pydub, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.3 pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install SpeechRecognition pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO1nWoWUfAOL",
        "outputId": "d894b33f-6b4a-4c99-e30d-3363a49b7f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n",
            "\n",
            "Full text: Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "def transcribe_audio(path):\n",
        "\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text\n",
        "\n",
        "def get_audio_transcription(path):\n",
        "\n",
        "    sound = AudioSegment.from_file(path)\n",
        "\n",
        "    chunks = split_on_silence(sound,\n",
        "\n",
        "        min_silence_len = 500,\n",
        "\n",
        "        silence_thresh = sound.dBFS-14,\n",
        "\n",
        "        keep_silence=500,\n",
        "    )\n",
        "    folder_name = \"audio-chunks\"\n",
        "\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "\n",
        "    return whole_text\n",
        "\n",
        "\n",
        "path = \"/content/Recording (6).m4a\"\n",
        "print(\"\\nFull text:\", get_audio_transcription(path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoz9-K5h4iI6",
        "outputId": "e2c9a353-8b73-4029-ae53-c172bf597bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ovz5myw4iFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "def tokenize_text(text):\n",
        "     tokens = word_tokenize(text)\n",
        "     return tokens\n",
        "\n",
        "transcribed_text = get_audio_transcription(path)\n",
        "tokens = tokenize_text(transcribed_text)\n",
        "print(\"\\nFull text:\", transcribed_text)\n",
        "print(\"\\nTokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbr1_4njGmYI",
        "outputId": "45ca0eee-553e-437b-d80d-d29891239d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n",
            "\n",
            "Full text: Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n",
            "\n",
            "Tokens: ['Hello', 'my', 'name', 'is', 'karar', 'and', 'today', 'i', \"'m\", 'testing', 'my', 'speech', 'to', 'text', 'module', 'for', 'my', 'system', 'ai', 'recruitment', 'assistant', 'for', 'hr', 'manager', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9MFEqPA638o",
        "outputId": "490b0aff-8998-4416-f601-d53fb40f6340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoMT-HpJ01sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e51761-7986-47f6-cc2b-0f64b072560a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Hello my name is karan today i'm testing speech to text module for my ai recruitment assistant for hr manager. \n",
            "\n",
            "Full text: Hello my name is karan today i'm testing speech to text module for my ai recruitment assistant for hr manager. \n",
            "Sentiment Polarity: 0.0 %\n",
            "Class: Neutral\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "def transcribe_audio(path):\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text\n",
        "\n",
        "def get_audio_transcription(path):\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    chunks = split_on_silence(sound,\n",
        "                              min_silence_len=500,\n",
        "                              silence_thresh=sound.dBFS-13,\n",
        "                              keep_silence=500)\n",
        "    folder_name = \"audio-chunks\"\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "    return whole_text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "def classify_sentiment(polarity):\n",
        "    if polarity > 0.1:\n",
        "        return \"Positive\"\n",
        "    elif polarity < -0.2:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "path = \"/content/Recording (4).m4a\"\n",
        "transcribed_text = get_audio_transcription(path)\n",
        "# tokens = tokenize(path)\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    processed_text = preprocess_text(text)\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    print(\"Sentiment Polarity:\", polarity*100,\"%\")\n",
        "    sentiment_class = classify_sentiment(polarity)\n",
        "    print(\"Class:\", sentiment_class)\n",
        "\n",
        "print(\"\\nFull text:\", transcribed_text)\n",
        "analyze_sentiment(transcribed_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSoh4ffcQKax",
        "outputId": "96d51c66-dbbb-48b6-c829-8a6eff88d9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake_nltk) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.66.2)\n",
            "Installing collected packages: rake_nltk\n",
            "Successfully installed rake_nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from rake_nltk import Rake\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "r = sr.Recognizer()\n",
        "\n",
        "def transcribe_audio(path):\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text\n",
        "\n",
        "def get_audio_transcription(path):\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    chunks = split_on_silence(sound,\n",
        "                              min_silence_len=500,\n",
        "                              silence_thresh=sound.dBFS-14,\n",
        "                              keep_silence=500)\n",
        "    folder_name = \"audio-chunks\"\n",
        "\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "        try:\n",
        "            text = transcribe_audio(chunk_filename)\n",
        "        except sr.UnknownValueError as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "\n",
        "    return whole_text\n",
        "\n",
        "def ext_keywords(text):\n",
        "\n",
        "    rake = Rake()\n",
        "    rake.extract_keywords_from_text(text)\n",
        "    keyword_list = rake.get_ranked_phrases()[:10]\n",
        "    return keyword_list\n",
        "\n",
        "path = \"/content/Recording (6).m4a\"\n",
        "transcribed_text = get_audio_transcription(path)\n",
        "\n",
        "print(\"\\nFull text:\", transcribed_text)\n",
        "print(\"\\nKeywords:\", ext_keywords(transcribed_text))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNYzrIszQEF3",
        "outputId": "f33c87c1-8c30-45e0-9183-26b53c1b995b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n",
            "\n",
            "Full text: Hello my name is karar and today i'm testing my speech to text module for my system ai recruitment assistant for hr manager. \n",
            "\n",
            "Keywords: ['system ai recruitment assistant', 'text module', 'hr manager', 'today', 'testing', 'speech', 'name', 'karar', 'hello']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqHeROzKfhXo"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "\n",
        "from google.cloud.speech_v2 import SpeechClient\n",
        "from google.cloud.speech_v2.types import cloud_speech\n",
        "from google.protobuf import duration_pb2  # type: ignore\n",
        "\n",
        "\n",
        "def transcribe_streaming_voice_activity_timeouts(\n",
        "    project_id: str,\n",
        "    speech_start_timeout: int,\n",
        "    speech_end_timeout: int,\n",
        "    audio_file: str,\n",
        ") -> cloud_speech.StreamingRecognizeResponse:\n",
        "\n",
        "\n",
        "    client = SpeechClient()\n",
        "\n",
        "\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "\n",
        "    chunk_length = len(content) // 20\n",
        "    stream = [\n",
        "        content[start : start + chunk_length]\n",
        "        for start in range(0, len(content), chunk_length)\n",
        "    ]\n",
        "    audio_requests = (\n",
        "        cloud_speech.StreamingRecognizeRequest(audio=audio) for audio in stream\n",
        "    )\n",
        "\n",
        "    recognition_config = cloud_speech.RecognitionConfig(\n",
        "        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
        "        language_codes=[\"en-US\"],\n",
        "        model=\"long\",\n",
        "    )\n",
        "\n",
        "    speech_start_timeout = duration_pb2.Duration(seconds=speech_start_timeout)\n",
        "    speech_end_timeout = duration_pb2.Duration(seconds=speech_end_timeout)\n",
        "    voice_activity_timeout = (\n",
        "        cloud_speech.StreamingRecognitionFeatures.VoiceActivityTimeout(\n",
        "            speech_start_timeout=speech_start_timeout,\n",
        "            speech_end_timeout=speech_end_timeout,\n",
        "        )\n",
        "    )\n",
        "    streaming_features = cloud_speech.StreamingRecognitionFeatures(\n",
        "        enable_voice_activity_events=True, voice_activity_timeout=voice_activity_timeout\n",
        "    )\n",
        "\n",
        "    streaming_config = cloud_speech.StreamingRecognitionConfig(\n",
        "        config=recognition_config, streaming_features=streaming_features\n",
        "    )\n",
        "\n",
        "    config_request = cloud_speech.StreamingRecognizeRequest(\n",
        "        recognizer=f\"projects/{project_id}/locations/global/recognizers/_\",\n",
        "        streaming_config=streaming_config,\n",
        "    )\n",
        "\n",
        "    def requests(config: cloud_speech.RecognitionConfig, audio: list) -> list:\n",
        "        yield config\n",
        "        for message in audio:\n",
        "            sleep(0.5)\n",
        "            yield message\n",
        "\n",
        "    responses_iterator = client.streaming_recognize(\n",
        "        requests=requests(config_request, audio_requests)\n",
        "    )\n",
        "\n",
        "    responses = []\n",
        "    for response in responses_iterator:\n",
        "        responses.append(response)\n",
        "        if (\n",
        "            response.speech_event_type\n",
        "            == cloud_speech.StreamingRecognizeResponse.SpeechEventType.SPEECH_ACTIVITY_BEGIN\n",
        "        ):\n",
        "            print(\"Speech started.\")\n",
        "        if (\n",
        "            response.speech_event_type\n",
        "            == cloud_speech.StreamingRecognizeResponse.SpeechEventType.SPEECH_ACTIVITY_END\n",
        "        ):\n",
        "            print(\"Speech ended.\")\n",
        "        for result in response.results:\n",
        "            print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
        "\n",
        "    return responses\n",
        "\n",
        "\n",
        "  #  key =\"1d9c69b994806fc731a8ac5d8da1c3a875251ee0\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDudN9HLjoFH65wQbUxLu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}