{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kararmirza19/kararmirza19/blob/main/CV_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwcSA4fhzft1",
        "outputId": "958bc192-cbab-42e7-d056-e71c55697f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textract in /usr/local/lib/python3.10/dist-packages (1.6.5)\n",
            "Requirement already satisfied: argcomplete~=1.10.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.10.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.8.0 in /usr/local/lib/python3.10/dist-packages (from textract) (4.8.2)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.10/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: extract-msg<=0.29.* in /usr/local/lib/python3.10/dist-packages (from textract) (0.28.7)\n",
            "Requirement already satisfied: pdfminer.six==20191110 in /usr/local/lib/python3.10/dist-packages (from textract) (20191110)\n",
            "Requirement already satisfied: python-pptx~=0.6.18 in /usr/local/lib/python3.10/dist-packages (from textract) (0.6.23)\n",
            "Requirement already satisfied: six~=1.12.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: SpeechRecognition~=3.8.1 in /usr/local/lib/python3.10/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: xlrd~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (3.20.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.5)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (0.47)\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (5.2)\n",
            "Requirement already satisfied: compressed-rtf>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
            "Requirement already satisfied: ebcdic>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx~=0.6.18->textract) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install textract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDp2CIVSzzul",
        "outputId": "8c236f58-f60a-42fe-af79-9f7f3d204e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import collections\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from joblib import dump, load\n",
        "import pickle\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from itertools import chain\n",
        "import textract\n",
        "from gensim.models import Word2Vec\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "import nltk\n",
        "import collections\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5DA-EQX0DYj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def cleanResume(resumeText):\n",
        "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)\n",
        "    resumeText = re.sub('RT|cc', ' ', resumeText)\n",
        "    resumeText = re.sub('#\\S+', '', resumeText)\n",
        "    resumeText = re.sub('@\\S+', '  ', resumeText)\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)\n",
        "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText)\n",
        "    resumeText = re.sub('\\s+', ' ', resumeText)\n",
        "    return resumeText\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-Kt1osg0HKg"
      },
      "outputs": [],
      "source": [
        "def Preprocessfile(filename):\n",
        "  text = textract.process(filename)\n",
        "  text= text.decode('utf-8').replace(\"\\n\", \" \")\n",
        "  x=[]\n",
        "  tokens=word_tokenize(text)\n",
        "  tok=[w.lower() for w in tokens]\n",
        "  table=str.maketrans('','',string.punctuation)\n",
        "  strpp=[w.translate(table) for w in tok]\n",
        "  words=[word for word in strpp if word.isalpha()]\n",
        "  stop_words=set(stopwords.words('english'))\n",
        "  words=[w for w in words if not w in stop_words]\n",
        "  x.append(words)\n",
        "  # print(x)\n",
        "  res=\" \".join(chain.from_iterable(x))\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2suI5wcG3xNp",
        "outputId": "d577dcf4-1fdf-42d6-b626-9a7ceac284a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tools\n",
            "  Downloading tools-0.1.9.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytils (from tools)\n",
            "  Downloading pytils-0.4.1.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tools) (1.12.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from tools) (4.9.4)\n",
            "Building wheels for collected packages: tools, pytils\n",
            "  Building wheel for tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tools: filename=tools-0.1.9-py3-none-any.whl size=46730 sha256=c9c3b6ab47689a55b719e6512092b11ebf94474f1fcdf8590a5585b26c869291\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/d0/70/a33bd4bed2af4f7038b038c16faab552cd0e9d9f4125223a71\n",
            "  Building wheel for pytils (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytils: filename=pytils-0.4.1-py3-none-any.whl size=32868 sha256=dba01e451df2a366e2dc6388d7d704f03b4fec03eef968dafefe061e0ef5c836\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/eb/7c/3b6f0c25815749883152b2caca34c35dbaab13ec2864270cbd\n",
            "Successfully built tools pytils\n",
            "Installing collected packages: pytils, tools\n",
            "Successfully installed pytils-0.4.1 tools-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install fileupload\n",
        "!pip install fitz\n",
        "!pip install frontend\n",
        "!pip install docx\n",
        "!pip install --upgrade python-docx\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Create the static directory if it doesn't exist\n",
        "# static_dir = \"static\"\n",
        "# if not os.path.exists(static_dir):\n",
        "#     os.makedirs(static_dir)\n",
        "\n",
        "!pip install tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlP-xlVu0OLG",
        "outputId": "24f31e6c-da8f-45eb-ef51-bfc358a204b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score for /content/M.Muzammil Khan Resume (1).pdf: 0.12%\n",
            "Similarity Score for /content/Yahya's Resume (2).pdf: 0.3%\n",
            "Similarity Score for /content/Resume.pdf: 0.85%\n",
            "Similarity Score for /content/my_Resume.pdf: 0.32%\n"
          ]
        }
      ],
      "source": [
        "# x=Preprocessfile('/content/job desc.txt')\n",
        "# y=Preprocessfile(\"/content/M.Muzammil Khan Resume.pdf\")\n",
        "# text=[y,x]\n",
        "# resume_paths = ['/content/M.Muzammil Khan Resume.pdf', \"/content/Yahya's Resume (2).pdf\", \"/content/MYCV.pdf\"]\n",
        "# print(\"\\n Similarity Score: \")\n",
        "# cv = CountVectorizer()\n",
        "# count_matrix = cv.fit_transform(text)\n",
        "# print(cosine_similarity(count_matrix))\n",
        "# matchpercent = cosine_similarity(count_matrix)[0][1]*100\n",
        "# matchpercent = round(matchpercent,2)\n",
        "\n",
        "# print(\"Your Resume matches about \" + str(matchpercent) + \"% of the job\")\n",
        "\n",
        "# resume_paths = ['/content/M.Muzammil Khan Resume.pdf', \"/content/Yahya's Resume (2).pdf\", \"/content/MYCV.pdf\"]\n",
        "\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# def preprocess_file(file_path):\n",
        "#     try:\n",
        "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#             text = file.read()\n",
        "#     except UnicodeDecodeError:\n",
        "#         with open(file_path, 'r', encoding='latin-1') as file:\n",
        "#             text = file.read()\n",
        "#     return text\n",
        "\n",
        "\n",
        "\n",
        "# job_description_path = '/content/job desc.txt'\n",
        "# job_description = preprocess_file(job_description_path)\n",
        "\n",
        "# resume_paths = ['/content/M.Muzammil Khan Resume.pdf', \"/content/Yahya's Resume (2).pdf\", \"/content/MYCV.pdf\"]\n",
        "\n",
        "# # Preprocess each resume and calculate similarity score\n",
        "# for resume_path in resume_paths:\n",
        "#     resume = preprocess_file(resume_path)\n",
        "#     text = [resume, job_description]\n",
        "\n",
        "#     cv = CountVectorizer()\n",
        "#     count_matrix = cv.fit_transform(text)\n",
        "#     similarity_score = cosine_similarity(count_matrix)[0][1]\n",
        "#     match_percent = round(similarity_score * 100,2)\n",
        "\n",
        "#     print(f\"Similarity Score for {resume_path}: {match_percent}%\")\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n",
        "    return lemmatized_text\n",
        "\n",
        "def calculate_similarity(resume, job_description):\n",
        "\n",
        "    preprocessed_resume = preprocess_text(resume)\n",
        "    preprocessed_job_desc = preprocess_text(job_description)\n",
        "\n",
        "\n",
        "    cv = CountVectorizer()\n",
        "    count_matrix = cv.fit_transform([preprocessed_resume, preprocessed_job_desc])\n",
        "    similarity_score = cosine_similarity(count_matrix)[0][1]\n",
        "    match_percent = round(similarity_score * 100 ,2)\n",
        "    return match_percent\n",
        "\n",
        "def read_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            text = file.read()\n",
        "    return text\n",
        "\n",
        "job_description_path = '/content/job desc.txt'\n",
        "job_description = read_file(job_description_path)\n",
        "\n",
        "resume_paths = ['/content/M.Muzammil Khan Resume (1).pdf', \"/content/Yahya's Resume (2).pdf\",\"/content/Resume.pdf\", \"/content/my_Resume.pdf\"]\n",
        "\n",
        "\n",
        "for resume_path in resume_paths:\n",
        "    resume = read_file(resume_path)\n",
        "    similarity_score = calculate_similarity(resume, job_description)\n",
        "    print(f\"Similarity Score for {resume_path}: {similarity_score}%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfzebWpRMRA6",
        "outputId": "c23cbc17-4f58-4174-efe7-13df4a769dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (67.7.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.3)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6 (from nipype->fitz)\n",
            "  Downloading traits-6.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.14.0)\n",
            "Collecting etelemetry>=0.2.0 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Collecting looseversion (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.2.2)\n",
            "Installing collected packages: looseversion, traits, simplejson, isodate, configparser, configobj, ci-info, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed ci-info-0.3.0 configobj-5.0.8 configparser-7.0.0 etelemetry-0.3.1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.8.6 prov-2.0.0 pyxnat-1.6.2 rdflib-7.0.0 simplejson-3.19.2 traits-6.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT8Fird-MeX0"
      },
      "outputs": [],
      "source": [
        "!pip install frontend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0_tQP2sNgJ8",
        "outputId": "3550beb6-e067-4a4b-b113-631e2061ab80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.2)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.1 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.1)\n"
          ]
        }
      ],
      "source": [
        "# mkdir static\n",
        "# !pip install tools\n",
        "# !pip install docx\n",
        "# !pip install PyMuPDF python-docx\n",
        "# !pip install --upgrade fitz\n",
        "!pip install PyMuPDF"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME8xEVfoePpA8I95p0cSep",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}